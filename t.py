import re
from dataclasses import dataclass
from typing import Dict, List, Tuple

import networkx as nx
import numpy as np
import pandas as pd
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


@dataclass
class Product:
    name: str
    efficacy: str
    ingredients: str
    crowd: str


class KnowledgeEngine:
    def __init__(self):
        self.graph = nx.DiGraph()
        self.products: List[Product] = self._seed_products()
        self.knowledge_docs = self._build_knowledge_docs()
        self.vectorizer = TfidfVectorizer()
        self.doc_matrix = self.vectorizer.fit_transform(self.knowledge_docs)
        self._build_graph()

    @staticmethod
    def _seed_products() -> List[Product]:
        return [
            Product("æ¶¦æ¸…é¥®A", "æ»‹é˜´æ¶¦ç‡¥", "éº¦å†¬,ç™¾åˆ,ç‰ç«¹", "ç»å¸¸ç†¬å¤œã€å£å¹²äººç¾¤"),
            Product("æ¸…å’ŒèŒ¶B", "æ¸…çƒ­é™ç«", "é‡‘é“¶èŠ±,èŠèŠ±,æ·¡ç«¹å¶", "æ˜“ä¸Šç«ã€å’½å–‰ä¸é€‚äººç¾¤"),
            Product("å…ƒæ°”è†C", "å¥è„¾ç›Šæ°”", "é»„èŠª,å…šå‚,èŒ¯è‹“", "ç–²åŠ³ä¹åŠ›ã€æ°”è™šäººç¾¤"),
        ]

    def _build_knowledge_docs(self) -> List[str]:
        docs = [
            "å£å¹²èˆŒç‡¥ å¸¸è§äº é˜´è™š å»ºè®® æ»‹é˜´ æ¶¦ç‡¥ æˆåˆ† éº¦å†¬ ç™¾åˆ ç‰ç«¹",
            "ä¸Šç« å’½å–‰ä¸é€‚ å¸¸è§äº å†…çƒ­åç›› å»ºè®® æ¸…çƒ­ é™ç« æˆåˆ† é‡‘é“¶èŠ± èŠèŠ±",
            "ç–²åŠ³ ä¹åŠ› é£Ÿæ¬²å·® å¸¸è§äº è„¾æ°”è™š å»ºè®® å¥è„¾ ç›Šæ°” æˆåˆ† é»„èŠª å…šå‚ èŒ¯è‹“",
        ]
        for p in self.products:
            docs.append(f"äº§å“ {p.name} åŠŸæ•ˆ {p.efficacy} æˆåˆ† {p.ingredients} é€‚ç”¨äººç¾¤ {p.crowd}")
        return docs

    def _build_graph(self):
        relations = [
            ("å£å¹²èˆŒç‡¥", "å¯¹åº”è¯å‹", "é˜´è™š"),
            ("é˜´è™š", "å»ºè®®åŠŸæ•ˆ", "æ»‹é˜´æ¶¦ç‡¥"),
            ("æ»‹é˜´æ¶¦ç‡¥", "æ¨èæˆåˆ†", "éº¦å†¬"),
            ("ä¸Šç«", "å¯¹åº”è¯å‹", "å†…çƒ­åç››"),
            ("å†…çƒ­åç››", "å»ºè®®åŠŸæ•ˆ", "æ¸…çƒ­é™ç«"),
            ("æ¸…çƒ­é™ç«", "æ¨èæˆåˆ†", "é‡‘é“¶èŠ±"),
            ("ç–²åŠ³ä¹åŠ›", "å¯¹åº”è¯å‹", "è„¾æ°”è™š"),
            ("è„¾æ°”è™š", "å»ºè®®åŠŸæ•ˆ", "å¥è„¾ç›Šæ°”"),
            ("å¥è„¾ç›Šæ°”", "æ¨èæˆåˆ†", "é»„èŠª"),
        ]
        for head, rel, tail in relations:
            self.graph.add_edge(head, tail, relation=rel)

        for p in self.products:
            self.graph.add_edge(p.name, p.efficacy, relation="äº§å“åŠŸæ•ˆ")
            for ing in p.ingredients.split(","):
                self.graph.add_edge(p.name, ing.strip(), relation="äº§å“æˆåˆ†")

    def add_product(self, name: str, efficacy: str, ingredients: str, crowd: str):
        self.products.append(Product(name, efficacy, ingredients, crowd))
        self.knowledge_docs.append(f"äº§å“ {name} åŠŸæ•ˆ {efficacy} æˆåˆ† {ingredients} é€‚ç”¨äººç¾¤ {crowd}")
        self.doc_matrix = self.vectorizer.fit_transform(self.knowledge_docs)
        self.graph.add_edge(name, efficacy, relation="äº§å“åŠŸæ•ˆ")
        for ing in ingredients.split(","):
            self.graph.add_edge(name, ing.strip(), relation="äº§å“æˆåˆ†")

    def rag_retrieve(self, query: str, top_k: int = 3) -> List[str]:
        q_vec = self.vectorizer.transform([query])
        sims = cosine_similarity(q_vec, self.doc_matrix)[0]
        idx = np.argsort(sims)[::-1][:top_k]
        return [self.knowledge_docs[i] for i in idx]

    def graph_hint(self, query: str) -> List[Tuple[str, str, str]]:
        hints = []
        for node in self.graph.nodes:
            if node in query:
                for succ in self.graph.successors(node):
                    rel = self.graph[node][succ]["relation"]
                    hints.append((node, rel, succ))
        return hints[:5]


class AgentPipeline:
    banned_words = ["æ²»ç–—", "æ ¹æ²»", "ç»å¯¹", "ä¿è¯", "æœ€æœ‰æ•ˆ", "æ²»æ„ˆ"]

    def __init__(self, engine: KnowledgeEngine):
        self.engine = engine

    def intent_agent(self, text: str) -> str:
        if any(k in text for k in ["æ–‡æ¡ˆ", "å°çº¢ä¹¦", "ç§è‰"]):
            return "content_generation"
        return "qa"

    def retrieve_agent(self, text: str) -> Dict[str, List]:
        return {
            "rag_docs": self.engine.rag_retrieve(text),
            "graph_hints": self.engine.graph_hint(text),
        }

    def generate_agent(self, text: str, context: Dict[str, List]) -> str:
        rag_text = "\n".join(context["rag_docs"])
        graph_text = "\n".join([f"{h} -[{r}]-> {t}" for h, r, t in context["graph_hints"]])
        if self.intent_agent(text) == "content_generation":
            return (
                "ã€è‰æœ¬æ™ºè¥Â·ç§è‰æ–‡æ¡ˆã€‘\n"
                f"ä¸»é¢˜ï¼š{text}\n\n"
                "æœ€è¿‘çŠ¶æ€ä¸åœ¨çº¿ï¼Ÿè¯•è¯•ä»æ—¥å¸¸è‰æœ¬è°ƒç†å¼€å§‹ã€‚\n"
                "ç»“åˆä½“è´¨ç‰¹ç‚¹ï¼Œé€‰æ‹©æ›´åŒ¹é…çš„é…æ–¹ï¼Œé‡åœ¨æ—¥å¸¸å…»æŠ¤ä¸å¹³è¡¡ã€‚\n\n"
                "ã€çŸ¥è¯†ä¾æ®ã€‘\n"
                f"{rag_text}\n\n"
                "ã€å›¾è°±å…³ç³»æç¤ºã€‘\n"
                f"{graph_text if graph_text else 'æš‚æ— ç›´æ¥å‘½ä¸­ï¼Œå·²åŸºäºè¯­ä¹‰æ£€ç´¢ç”Ÿæˆã€‚'}"
            )
        return (
            "ã€æ™ºèƒ½é—®ç­”å›å¤ã€‘\n"
            f"é—®é¢˜ï¼š{text}\n\n"
            "å¯å…ˆä»ä½œæ¯ã€é¥®é£Ÿå’Œä½“è´¨è°ƒç†å…¥æ‰‹ï¼Œä»¥ä¸‹æ˜¯æ£€ç´¢åˆ°çš„ç›¸å…³çŸ¥è¯†ï¼š\n"
            f"{rag_text}\n\n"
            "å›¾è°±å…³ç³»ï¼š\n"
            f"{graph_text if graph_text else 'æš‚æ— ç›´æ¥å‘½ä¸­å…³ç³»ã€‚'}\n\n"
            "ä»¥ä¸Šå†…å®¹ä»…ç”¨äºå¥åº·ç§‘æ™®ï¼Œä¸æ›¿ä»£åŒ»ç”Ÿè¯Šç–—å»ºè®®ã€‚"
        )

    def compliance_agent(self, content: str) -> List[str]:
        risks = []
        for w in self.banned_words:
            if re.search(re.escape(w), content):
                risks.append(f"æ£€æµ‹åˆ°é«˜é£é™©è¯ï¼š{w}")
        if not risks:
            risks.append("æœªæ£€æµ‹åˆ°æ˜æ˜¾é«˜é£é™©åŒ»ç–—å®£ç§°è¯ã€‚")
        return risks


@st.cache_resource
def init_system() -> AgentPipeline:
    engine = KnowledgeEngine()
    return AgentPipeline(engine)


def main():
    st.set_page_config(page_title="è‰æœ¬æ™ºè¥ - æ™ºèƒ½è¥é”€ç³»ç»Ÿ", page_icon="ğŸŒ¿", layout="wide")
    st.title("è‰æœ¬æ™ºè¥ï¼šä¸­åŒ»ä¼ä¸šæ™ºèƒ½è¥é”€ç³»ç»Ÿï¼ˆè¯¾ç¨‹è®¾è®¡MVPï¼‰")

    pipeline = init_system()
    engine = pipeline.engine

    tab1, tab2, tab3, tab4 = st.tabs(["äº§å“çŸ¥è¯†ä¸Šä¼ ", "å°çº¢ä¹¦å†…å®¹ç”Ÿæˆ", "æ™ºèƒ½å®¢æœé—®ç­”", "åˆè§„æ£€æµ‹"])

    with tab1:
        st.subheader("1) äº§å“çŸ¥è¯†ä¸Šä¼ ")
        with st.form("product_form"):
            name = st.text_input("äº§å“åç§°")
            efficacy = st.text_input("äº§å“åŠŸæ•ˆ")
            ingredients = st.text_input("äº§å“æˆåˆ†ï¼ˆç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼‰")
            crowd = st.text_input("ç›®æ ‡äººç¾¤")
            submitted = st.form_submit_button("ä¸Šä¼ å¹¶ç»“æ„åŒ–å­˜å‚¨")
            if submitted:
                if not (name and efficacy and ingredients and crowd):
                    st.warning("è¯·å®Œæ•´å¡«å†™æ‰€æœ‰å­—æ®µã€‚")
                else:
                    engine.add_product(name, efficacy, ingredients, crowd)
                    st.success(f"å·²ä¸Šä¼ ï¼š{name}")

        df = pd.DataFrame([p.__dict__ for p in engine.products])
        st.dataframe(df, use_container_width=True)

    with tab2:
        st.subheader("2) ä¸€é”®ç”Ÿæˆå°çº¢ä¹¦å†…å®¹")
        topic = st.text_input("è¾“å…¥ä¸»é¢˜ï¼ˆå¦‚ï¼šæ¶¦æ¸…é¥®A + ç†¬å¤œå£å¹²äººç¾¤ï¼‰", key="topic")
        if st.button("ç”Ÿæˆç§è‰æ–‡æ¡ˆ"):
            if not topic.strip():
                st.warning("è¯·è¾“å…¥ä¸»é¢˜ã€‚")
            else:
                ctx = pipeline.retrieve_agent(topic)
                content = pipeline.generate_agent(topic + " å°çº¢ä¹¦ç§è‰æ–‡æ¡ˆ", ctx)
                st.text_area("ç”Ÿæˆç»“æœ", content, height=260)

    with tab3:
        st.subheader("3) æ™ºèƒ½é—®ç­”å®¢æœ")
        q = st.text_input("è¯·è¾“å…¥ç”¨æˆ·é—®é¢˜ï¼ˆå¦‚ï¼šæœ€è¿‘å®¹æ˜“ä¸Šç«æ€ä¹ˆåŠï¼Ÿï¼‰", key="qa")
        if st.button("ç”Ÿæˆé—®ç­”å›å¤"):
            if not q.strip():
                st.warning("è¯·è¾“å…¥é—®é¢˜ã€‚")
            else:
                ctx = pipeline.retrieve_agent(q)
                answer = pipeline.generate_agent(q, ctx)
                st.text_area("é—®ç­”ç»“æœ", answer, height=260)

    with tab4:
        st.subheader("4) åˆè§„æ£€æµ‹")
        text = st.text_area("ç²˜è´´å¾…æ£€æµ‹æ–‡æœ¬", "æœ¬äº§å“å¯æ²»ç–—ä¸Šç«å¹¶ä¿è¯è§æ•ˆã€‚", height=180)
        if st.button("æ‰§è¡Œåˆè§„æ£€æµ‹"):
            risks = pipeline.compliance_agent(text)
            for item in risks:
                if "é«˜é£é™©" in item:
                    st.error(item)
                else:
                    st.success(item)


if __name__ == "__main__":
    main()
